<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html lang="en">
<head>
<META http-equiv="Content-Type" content="text/html; charset=UTF-8">
<!--
This HTML was auto-generated from MATLAB code.
To make changes, update the MATLAB code and republish this document.
      -->
<title>DeepMIB - Directories and Preprocessing tab</title>
<meta name="generator" content="MATLAB 23.2">
<link rel="schema.DC" href="http://purl.org/dc/elements/1.1/">
<meta name="DC.date" content="2024-03-07">
<meta name="DC.source" content="ug_gui_menu_tools_deeplearning_dirs.m">
<style>
html,body,div,span,applet,object,iframe,h1,h2,h3,h4,h5,h6,p,blockquote,pre,a,my-a,abbr,acronym,address,big,cite,code,del,dfn,em,font,img,ins,kbd,q,s,samp,small,strike,strong,tt,var,b,u,i,center,dl,dt,dd,ol,ul,li,fieldset,form,label,legend,table,caption,tbody,tfoot,thead,tr,th,td{margin:0;padding:0;border:0;outline:0;font-size:100%;vertical-align:baseline;background:transparent}body{line-height:1}ol,ul{list-style:none}blockquote,q{quotes:none}blockquote:before,blockquote:after,q:before,q:after{content:'';content:none}ins{text-decoration:none}del{text-decoration:line-through}table{border-collapse:collapse;border-spacing:0}

html { min-height:100%; margin-bottom:1px; }
html body { height:100%; margin:0px; font-family:Arial, Helvetica, sans-serif; font-size:10px; color:#000; line-height:140%; background:#fff none; overflow-y:scroll; }
html body td { vertical-align:top; text-align:left; }

h1 { padding:0px; margin:0px 0px 25px; font-family:Arial, Helvetica, sans-serif; font-size:1.5em; color:#d55000; line-height:100%; font-weight:normal; }
h2 { padding:0px; margin:0px 0px 8px; font-family:Arial, Helvetica, sans-serif; font-size:1.2em; color:#000; font-weight:bold; line-height:140%; border-bottom:1px solid #d6d4d4; display:block; }
h3 { padding:0px; margin:0px 0px 5px; font-family:Arial, Helvetica, sans-serif; font-size:1.1em; color:#000; font-weight:bold; line-height:140%; }

a,my-a { color:#005fce; text-decoration:none; }
my-a:hover { cursor: pointer; }
a:hover,my-a:hover { color:#005fce; text-decoration:underline; }
a:visited { color:#004aa0; text-decoration:none; }

p { padding:0px; margin:0px 0px 20px; }
img { padding:0px; margin:0px 0px 20px; border:none; }
p img, pre img, tt img, li img, h1 img, h2 img { margin-bottom:0px; }

ul { padding:0px; margin:0px 0px 20px 23px; list-style:square; }
ul li { padding:0px; margin:0px 0px 7px 0px; }
ul li ul { padding:5px 0px 0px; margin:0px 0px 7px 23px; }
ul li ol li { list-style:decimal; }
ol { padding:0px; margin:0px 0px 20px 0px; list-style:decimal; }
ol li { padding:0px; margin:0px 0px 7px 23px; list-style-type:decimal; }
ol li ol { padding:5px 0px 0px; margin:0px 0px 7px 0px; }
ol li ol li { list-style-type:lower-alpha; }
ol li ul { padding-top:7px; }
ol li ul li { list-style:square; }

.content { font-size:1.2em; line-height:160%; padding: 20px; }

pre { font-size:12px; }
code { font-size: 1.15em; }
pre { margin:0px 0px 15px; overflow-x:auto; }
pre.codeinput { padding:10px; border:1px solid #d3d3d3; background:#f7f7f7; }
pre.codeoutput { padding:10px 11px; margin:0px 0px 15px; color:#4c4c4c; }
pre.error { color:red; }

@media print { pre.codeinput, pre.codeoutput { word-wrap:break-word; width:100%; } }

span.keyword { color:#0000FF }
span.comment { color:#228B22 }
span.string { color:#A020F0 }
span.untermstring { color:#B20000 }
span.syscmd { color:#B28C00 }
span.typesection { color:#A0522D }

.footer { width:auto; padding:10px 0px; margin:25px 0px 0px; border-top:1px dotted #878787; font-size:0.8em; line-height:140%; font-style:italic; color:#878787; text-align:left; float:none; }
.footer p { margin:0px; }
.footer a { color:#878787; }
.footer a:hover { color:#878787; text-decoration:underline; }
.footer a:visited { color:#878787; }

table th { padding:7px 5px; text-align:left; vertical-align:middle; border: 1px solid #d6d4d4; font-weight:bold; }
table td { padding:7px 5px; text-align:left; vertical-align:top; border:1px solid #d6d4d4; }




.dropdown { font-family: monospace; border: 1px solid #aaa; border-radius: 0.2em; background-color: #fffce8; padding: 0.1em 0.4em; font-family: inherit; font-size: 1em; }
.kbd { font-family: monospace; border: 1px solid #aaa; -moz-border-radius: 0.2em; -webkit-border-radius: 0.2em; border-radius: 0.2em; -moz-box-shadow: 0.1em 0.2em 0.2em #ddd; -webkit-box-shadow: 0.1em 0.2em 0.2em #ddd; box-shadow: 0.1em 0.2em 0.2em #ddd; background-color: #f9f9f9; background-image: -moz-linear-gradient(top, #eee, #f9f9f9, #eee); background-image: -o-linear-gradient(top, #eee, #f9f9f9, #eee); background-image: -webkit-linear-gradient(top, #eee, #f9f9f9, #eee); background-image: linear-gradient([[:Template:Linear-gradient/legacy]], #eee, #f9f9f9, #eee); padding: 0.1em 0.4em; font-family: inherit; font-size: 1em; }
.h3 { color: #E65100; font-size: 12px; font-weight: bold; }
.code { font-family: monospace; font-size: 10pt; background: #eee; padding: 1pt 3pt; }
.info { position: relative; left: 40px; width: 600px; padding: 1em 1em 1em 4em; margin: 2em 0; color: #555; background: #e7f2fa; border-left: 4px solid #93cfeb; }
.info:before { content: url(images\\info.png); position: absolute; top: 10px; left: 10px; }

#tooltiptext {
  visibility: hidden;
  padding: 5px 10px;
  font-size: 75%;
  line-height:110%;
  text-align: center;
  background-color: black;
  color: #ddd;
  border-radius: 6px;
  position: fixed;
  bottom: 11px;
  right: 62px;
  z-index: 2;
}
#tooltiptext::after {
  content: " ";
  position: absolute;
  top: 50%;
  left: 100%;
  margin-top: -5px;
  border-width: 5px;
  border-style: solid;
  border-color: transparent transparent transparent black;
}
.tooltip:hover #tooltiptext {
  visibility: visible;
}
#return-link {
    position: fixed;
    bottom: 10px;
    right: 10px;
    overflow: visible;
    font-size:120%;
    background: rgba(0, 0, 0, 0.75);
    border-style: solid;
    border-width: 3pt;
    border-color: #202020;
    border-radius: 4px;
    cursor: pointer;
    }
#return-link > p { padding:3px; margin:0; color:#C0C0C0;}
.MATLAB-Help {
width: 100%;
margin-bottom: 12px;
border: 1px solid #ccc;
border-right: none;
border-bottom: none;
font-size: 96%;
line-height: 1.4;
table-layout: fixed;
overflow:hidden;}

.MATLAB-Help > thead > tr > th {
padding: 6px 5px;
border: none;
border-right: 1px solid #ccc;
border-bottom: 1px solid #ccc;
background: #F2F2F2;
color: #000;
font-weight: bold;
text-align: left;
vertical-align: middle;}

.MATLAB-Help td{padding: 5px 5px;
border: none;
border-right: 1px solid #ccc;
border-bottom: 1px solid #ccc;
vertical-align: middle;}

.language-matlab { line-height:135% }

.collapse-link {float:right; line-height:200%; padding-left:10px; margin:0}


details > summary,
.details-div {
  padding: 8px 20px;
  border-style: solid;
  border-width: 1.2pt;
  border-color: #E0E0E0;
}
details > summary {
  border-radius:6px 6px 0 0;
  background-color: #F2F2F2;
  cursor: pointer;
}
.details-div {
  border-top-style: none;
  border-radius: 0 0 6px 6px;
}
.image-fit-svg,
.image-fit {
    max-width:  95%;
    max-height: 100%;
    margin:     auto;
}
.image-fit-svg{ padding:0px; max-width:500px; }
details > img.image-fit-svg{ padding: 0px 0px 10px; }
@media (max-width: 580px) {
  .image-fit-svg { max-width: 95%; }
}
.pretty-link  { color:#001188 !important; }
</style>
<style id="dark-theme">
    h2, h3       { color: #B0B0B0; }
    html body    { background-color: #101010; color: #B0B0B0; }
    .pretty-link { color: #C46313 !important; }
    a, a:visited, my-a  { color: #C46313 }
    a:hover, my-a:hover { color: orange; }
    details > summary,
    .details-div      { border-color:     #505050; }
    details > summary { background-color: #202020; }
    pre.codeinput     { border-width: 1.2pt; border-color:#001B33; background:#001129; color:#F0F0F0; }
    pre.codeoutput    { color:#A5A5A5; }
    span.keyword      { color:#FF9D00; }
    span.comment      { color:#808080; }
    span.string       { color:#3AD900; }
    span.untermstring { color:#FFEE80; }
    span.syscmd       { color:#CCCCCC; }
    .MATLAB-Help, .MATLAB-Help > thead > tr > th, .MATLAB-Help td { border-color:#505050; }
    .MATLAB-Help > thead > tr > th { background: #202020; color: #B0B0B0; }
    .summary-sub-heading { color:#909090; }
    .show-if-light    { display:none }
</style>
<style id="hide-dark">
     .show-if-dark { display:none }
</style>

<style id="anchor-offsets">
    h2::before, a[id]::before{
    content: "";
    display: block;
    height: 100px;
    margin: -100px 0 0;
    visibility: hidden;
    width:10%;
    z-index: -1;
}
</style>

<script>
          var returnElem = null;
          var skipCheck  = false;

          function hide_back_link()
          {
              returnButton.style.display = "none";
              try{
                 window.removeEventListener("scroll", update_back_position, true);
                 window.removeEventListener("resize", update_back_position, true);
                 parent.window.removeEventListener("scroll", update_back_position, true);
                 parent.window.removeEventListener("resize", update_back_position, true);}
              catch(e){}
          }

          function get_offset(element)
          {
              if (!element.getClientRects().length){ return { top: 0, left: 0 }; }
              var rect = element.getBoundingClientRect();
              var win  = element.ownerDocument.defaultView;
              return ( {top:  rect.top  + win.pageYOffset,
                        left: rect.left + win.pageXOffset} );
          }

          function jump_to()
          {
              var clickedElem = event.target;
              var clickedID   = clickedElem.closest("span");
              if (clickedID){
                clickedID = clickedID.getAttribute("id");
                if (clickedID.localeCompare("jump-close")===0) { return };}
              clickedID = clickedElem.closest("div").getAttribute("id");
              if (clickedID && clickedID.localeCompare("return-link")===0)
              {
                  if (returnElem)
                  {
                      event.preventDefault();
                      hide_back_link();
                      returnElem.scrollIntoView();
                      if (contentDiv.getAttribute("data-isHelpBrowser")){
                         contentDiv.scrollTop = contentDiv.scrollTop-100; }
                      if (contentDiv.getAttribute("data-isMATLABCentral")){
                         parent.window.scrollBy(0,-100)}
                      returnElem = null;
                  }
              }
              else
              {
                  var href = clickedElem.closest("my-a").getAttribute("href");
                  if ( href && href[0] == "#" )
                  {
                     var target = document.getElementById(href.substring(1));
                     var enclosingBox = target;
                     while ( enclosingBox )
                     {
                        prevBox      = enclosingBox;
                        enclosingBox = enclosingBox.closest("details");
                        if ( enclosingBox===prevBox ){
                           enclosingBox = enclosingBox.parentElement
                           if ( enclosingBox ) { enclosingBox = enclosingBox.closest("details"); }  }
                        if (enclosingBox && !enclosingBox.open) { open_details(enclosingBox.id) }
                     }
                     if (target){
                        event.preventDefault();
                        target.scrollIntoView(); }
                     var nextElem = target.nextElementSibling;
                     var nextNode = target.nextSibling;
                     while ( nextNode && nextNode.nodeType==Node.TEXT_NODE && nextNode.data.trim().length == 0 ){
                        nextNode = nextNode.nextSibling;}
                     if ( nextElem && nextElem===nextNode && nextElem.localName.localeCompare("details")===0 && !nextElem.open){
                        open_details(nextElem.id);}
                  }
                  else { return }
                  if (!contentDiv.getAttribute("data-isHelpBrowser"))
                  {
                      update_back_position();
                      returnButton.style.display = "block";
                      var linkTop   = clickedElem.offsetTop;
                      var targetTop = target.offsetTop;
                      if (targetTop>linkTop){
                          document.getElementById("down").style.display = "none";
                          document.getElementById("up").style.display   = "inline"; }
                      else{
                          document.getElementById("up").style.display   = "none";
                          document.getElementById("down").style.display = "inline"; }
                      returnElem = clickedElem;
                  }
              }
          }

          function open_details(detailsID)
          {
              var details  = document.getElementById(detailsID);
              skipCheck    = true;
              state_check(details.id);
              details.open = true;
          }

          function update_back_position()
          {
              try
              {
                  window.addEventListener("scroll", update_back_position, true);
                  window.addEventListener("resize", update_back_position, true);
                  var scrollPos;
                  if (in_iFrame())
                  {
                      parent.window.addEventListener("scroll", update_back_position, true);
                      parent.window.addEventListener("resize", update_back_position, true);
                      var iFrame         = window.frameElement;
                      var frameOffset    = get_offset(iFrame);
                      var documentBottom = parent.window.innerHeight  + parent.window.scrollY;
                      var extHeight      = Math.round(frameOffset.top + iFrame.getBoundingClientRect().height - documentBottom);
                      if (extHeight<0) { extHeight = 0; }
                      returnButton.style.bottom = (10+extHeight) + "px";
                      document.getElementById("tooltiptext").style.bottom = (11+extHeight) + "px";
                      scrollPos = contentDiv.scrollTop - 25 + iFrame.getBoundingClientRect().height - extHeight;
                  }
                  else{
                      scrollPos = window.scrollY + window.innerHeight - 25;}
                  if (returnElem.offsetTop>scrollPos){
                      document.getElementById("down").style.display = "inline";
                      document.getElementById("up").style.display   = "none";   }
                  else{
                      document.getElementById("down").style.display = "none";
                      document.getElementById("up").style.display   = "inline"; }
              }
              catch(e){}
          }
          function set_theme(themePref)
          {
            var themeSwitch     = document.getElementById("ToggleTheme");
            var themeSwitchText = "switch to";
            var switchToText    = null;
            if (!themePref){ themePref = get_theme_pref(); }
            if (themePref.localeCompare("light")===0){
                document.getElementById("dark-theme").sheet.disabled = true;
                document.getElementById("hide-dark").sheet.disabled  = false;
                switchToText = " dark theme";}
            else{
                document.getElementById("dark-theme").sheet.disabled = false;
                document.getElementById("hide-dark").sheet.disabled  = true;
                switchToText = " light theme";}
            themeSwitch.innerHTML = themeSwitchText + switchToText;
            set_theme_pref(themePref);
          }

          function toggle_theme()
          {
            if (document.getElementById("dark-theme").sheet.disabled) { set_theme("dark");  }
            else                                                      { set_theme("light"); }
          }

          function set_theme_pref(themePref)
          {
              var d = new Date();
              d.setTime(d.getTime() + (2*365*24*60*60*1000));
              var expires = "expires="+ d.toUTCString();
              document.cookie = "themepref=" + themePref + ";" + expires + "path=/";
              localStorage.setItem("PRETTY_THEME", themePref);
          }

          function get_theme_pref() {
              var name = "themepref=";
              var decodedCookie = decodeURIComponent(document.cookie);
              var ca = decodedCookie.split(';');
              for(var i = 0; i < ca.length; i++) {
                var c = ca[i];
                while (c.charAt(0) == ' ') {
                  c = c.substring(1);
                }
                if (c.indexOf(name) == 0) {
                  return c.substring(name.length, c.length);
                }
              }
              var docTheme = localStorage.getItem("PRETTY_THEME");
              if (docTheme) { return docTheme }
              else          { return "light"  }
          }

          function toggle_details(section)
          {
            var link;
            var subSection;
            var details;
            var linkText;
            var i;
            var openState  = true;
            var border     = "6px 6px 0 0;"
            if (section===0)
            {
              link = document.getElementById("Toggle"+section.toString());
              if (link.innerHTML.localeCompare("collapse all on page")===0){
                  openState = false;
                  border    = "6px;"
                  linkText  = "expand all";}
              else{
                  linkText   = "collapse all";}
              link.innerHTML = linkText + " on page";
              for (i = 0; i < allDetails.length; i++){
                 allDetails[i].open = openState;
                 allDetails[i].children[0].setAttribute( 'style', "border-radius:"+border );
                 link = document.getElementById("Toggle"+allDetails[i].id.split(".", 1));
                 if (allDetails[i].id.charAt(0).localeCompare("0") && link){link.innerHTML = linkText;}}
            }
            else
            {
               link = document.getElementById("Toggle"+section.toString());
               subSection = 1;
               if (link.innerHTML.localeCompare("collapse all")===0){
                  openState      = false;
                  border         = "6px;"
                  link.innerHTML = "expand all";}
               else{
                  link.innerHTML = "collapse all";}
               details = document.getElementById(section.toString()+"."+subSection.toString());
               while (details){
                    details.open = openState;
                    details.children[0].setAttribute( 'style', "border-radius:"+border );
                    subSection++;
                    details = document.getElementById(section.toString()+"."+subSection.toString());}
               var allCollapsed = true;
               var allExpanded  = true;
               for (i = 0; i < allDetails.length; i++){
                   check_if_open(allDetails[i]);}
               link = document.getElementById("Toggle0");
               if (allExpanded) {link.innerHTML = "collapse all on page";}
               if (allCollapsed){link.innerHTML = "expand all on page";}
            }
            function check_if_open(details)
            {
                if (details.open){allCollapsed = false;}
                else             {allExpanded  = false;}
            }
          }

          function state_check(detailsID)
          {
              // first deal with just the section
              if (event.detail){document.activeElement.blur();}
              var clickedElem   = event.target;
              if (!skipCheck && clickedElem.localName.localeCompare("summary"))
              { 
                if (!(clickedElem.closest("summary"))) { return };
              };
              var details       = document.getElementById(detailsID);
              if ( !skipCheck ) {
                  var parentID  = clickedElem.closest("details").id;
                  if (details.id.localeCompare(parentID)) { return };}
              skipCheck         = false;
              var clickedStatus = details.open;
              var section       = detailsID.split(".", 1);
              var subSection    = 1;
              var allCollapsed  = true;
              var allExpanded   = true;
              var link          = document.getElementById("Toggle"+section);
              if (clickedStatus) { details.children[0].setAttribute( 'style', "border-radius:6px;" ); }
              else               { details.children[0].setAttribute( 'style', "border-radius:6px 6px 0 0;" ); }
              if (link)
              {
                  details = document.getElementById(section+"."+subSection.toString());
                  while (details){
                    check_if_open(details);
                    subSection++;
                    details = document.getElementById(section+"."+subSection.toString());}
                  if (allExpanded) {link.innerHTML = "collapse all";}
                  if (allCollapsed){link.innerHTML = "expand all";}
              }
              // then the whole page
              allCollapsed   = true;
              allExpanded    = true;
              for (var i = 0; i < allDetails.length; i++){
                  check_if_open(allDetails[i]);}
              link = document.getElementById("Toggle0");
              if (allExpanded) {link.innerHTML = "collapse all on page";}
              if (allCollapsed){link.innerHTML = "expand all on page";}

              function check_if_open(details)
              {
                  var openStatus
                  if (detailsID.localeCompare( details.id )===0 ){openStatus = !clickedStatus;}
                  else                                           {openStatus = details.open;}
                  if (openStatus){allCollapsed = false;}
                  else           {allExpanded  = false;}
              }
          }

          function in_iFrame ()
          {
               try {
                   return window.self !== window.top;
               } catch (e) {
                   return true;
               }
          }
</script>

</head>
<body>
<div class="content">
<div id="return-link" style="display:none;" class="tooltip">
<p onclick="jump_to()">
    <span onclick="jump_to()"><span id="up">&#8679;</span><span id="down">&#8681;</span>
    <span onclick="hide_back_link()" style="padding:2px; font-size:120%;" id="jump-close"><b onclick="hide_back_link()">&times;</b></span></span>
</p>
<div id="tooltiptext">click to return
<br>(click <b>&times;</b> to hide)</div>
</div><script>document.getElementById("dark-theme").sheet.disabled = true;</script>
<h1>DeepMIB - Directories and Preprocessing tab</h1>
<!--introduction-->
<p>This tab allows choosing directories with images for training and prediction as well as various parameters used during image loading and preprocessing</p>
<p>
<b>Back to</b> <a href="im_browser_product_page.html"><b>Index</b></a> <code><b>--&gt;</b></code> <a href="im_browser_user_guide.html"><b>User Guide</b></a> <code><b>--&gt;</b></code> <a href="ug_gui_menu.html"><b>Menu</b></a> <code><b>--&gt;</b></code> <a href="ug_gui_menu_tools.html"><b>Tools Menu</b></a> <code><b>--&gt;</b></code> <a href="ug_gui_menu_tools_deeplearning.html"><b>Deep learning segmentation</b></a>
</p>
<!--/introduction-->
<p style="margin:0px; line-height:0;">&nbsp;</p>
<p onclick="toggle_details(0)" class="collapse-link"><a href="javascript:void(0);" id="Toggle0">collapse all on page</a></p><h2>Contents</h2>
<div>
<ul>
<li>
<my-a onclick="jump_to()" href="#1">Widgets and settings</my-a>
</li>
<li>
<my-a onclick="jump_to()" href="#2">Preprocessing of files</my-a>
</li>
<li>
<my-a onclick="jump_to()" href="#3">Organization of directories without preprocessing for semantic segmentation</my-a>
</li>
<li>
<my-a onclick="jump_to()" href="#4">Organization of directories with preprocessing for semantic segmentation</my-a>
</li>
<li>
<my-a onclick="jump_to()" href="#5">Organization of directories for 2D patch-wise workflow</my-a>
</li>
</ul>
</div>
<p style="margin:0px; line-height:0;">&nbsp;</p>
<p onclick="toggle_details(1)" class="collapse-link"><a href="javascript:void(0);" id="Toggle1">collapse all</a></p><h2 id="1">Widgets and settings</h2>
<p>
<img class="image-fit" src="images\DeepLearning_FileTree.jpg" alt=""> </p>
<p><span class="h3">Directory with images and labels for training</span>
<br> [ <i>used only for training</i> ]
<br></p>
<p>
<img class="image-fit" src="images\DeepLearningDirs_panel1.png" alt=""> </p>
<p>
use these widgets to select directory that contain images and model to be
used for training. For the organization of directories see the
organization schemes below.
<br>
For 2D networks the files should contain individual 2D images, while for 3D networks
individual 3D datasets.
<br>
The <span class="dropdown">extension &#9660;</span> dropdown menu on the right-hand side can be used to specify extension
of the image files. 
<br>
The <span class="kbd">[&#10003;] <b>Bio</b></span> checkbox toggles standard or Bio-format readers for loading images.
If the Bio-Format file is a collection of image, the <span class="dropdown">Index...</span> edit box can be used
to specify an index of the file within the container.
<br>
For better performance, it is recommended to convert Bio-Formats compatible images to standard formats or to use the Preprocessing option (see below).

<br>
</p>
<details open onclick="state_check('1.1')" id="1.1"><summary> <b>Important notes considering training files</b> </summary>
<div class="details-div">
<p></p>

<ul>
<li>Number of model or mask files should match the number of image files
(one exception is 2D networks, where it is allowed to have a single
model file in MIB <span class="code">*.model</span> format, when <b>Single MIB model file:
ticked</b>). This option requires <my-a onclick="jump_to()" href="#target2">data preprocessing</my-a></li>
<li>For labels in standard image formats it is important to
specify number of classes <b>including the Exterior</b> into the <b>Number of
classes</b> edit box</li>
<li><b><em>Important! It is not possible to use numbers as names of
materials, please name materials in a sensible way when using the <span class="code">*.model</span> format!</b></em></li>
</ul>


</div>
</details>
<br>
<p> <span style="line-height:8px; display:block; vertical-align:top">
<br></span></p>
<p><span class="h3">Directory with images for prediction</span>
<br> [ <i>used only for prediction</i> ]
<br> use these widgets to specify directory with images for prediction (named <span class="code">2_Prediction</span> in <my-a onclick="jump_to()" href="#target1">the file organization schemes below</my-a>).</p>
<p>
<img class="image-fit" src="images\DeepLearningDirs_panel2.png" alt=""> </p>
<p>
The image files should be placed under <span class="code">Images</span> subfolder
(it is also possible to place images directly into a folder specified in this panel).
Optionally, when the ground truth labels for prediction images are available, they can be placed under <span class="code">Labels</span> subfolder.

<br>
<br>
When the preprocessing mode is used the images from this folder are
converted and saved to <span class="code">3_Results\Prediction images</span> directory.
When the ground truth labels are present, they are also processed and copied to
<span class="code">3_Results\PredictionImages\GroundTruthLabels</span>. These labels can
be used for evaluation of results (see <ug_gui_menu_tools_deeplearning_predict.html the *Predict* tab> for details).

<br>
<br>
For 2D networks the files should contain individual 2D images or 3D stacks, while for 3D networks
individual 3D datasets.

<br>
<br>
The <span class="dropdown">extension &#9660;</span> dropdown menu on the right-hand side can be used to specify extension
of the image files. The <span class="kbd">[&#10003;] <b>Bio</b></span> checkbox toggles standard or Bio-format readers for loading the images.
If the Bio-Format file is a collection of image, the <b>Index</b> edit box can be used
to specify an index of the file within the container.
<br>
</p>
<p><span style="line-height:8px; display:block; vertical-align:top">
<br></span> <span class="h3">Directory with resulting images</span>
<br> use these widgets to specify the main output directory; results and all preprocessed images are stored there.</p>
<p>
<img class="image-fit" src="images\DeepLearningDirs_panel3.png" alt=""> </p>
<p>All subfolders inside this directory are automatically created by Deep MIB:<span style="line-height:8px; display:block; vertical-align:top">
<br></span></p>
<details open onclick="state_check('1.2')" id="1.2"><summary> <b>Description of directories created by DeepMIB</b> </summary>
<div class="details-div">
<p></p>

<ul>
<li><span class="code">PredictionImages</span>, place for the prepocessed images for
prediction</li>
<li><span class="code">PredictionImages\GroundTruthLabels</span>, place
for ground truth labels for prediction images, when available</li>
<li><span class="code">PredictionImages\ResultsModels</span>, the main outout directory with generated labels after prediction.
The 2D models can be combined in MIB by selecting the files using the <span class="kbd">&#8679; Shift</span>+<span class="kbd">left mouse click</span> during loading</li>
<li><span class="code">PredictionImages\ResultsScores</span>, folder for generated prediction scores (probability) for each material.
The score values are scaled between 0 and 255</li>
<li><span class="code">ScoreNetwork</span>, for accuracy and loss score plots, when the <em>Export training plots</em> option
of the <em>Train</em> tab is ticked and for storing checkpoints of the network after each epoch (or specified frequency),
when the <span class="kbd">[&#10003;] <b>Save progress after each epoch</b></span> checkbox is ticked. The score files are started with a date-time tag and overwritten when a new training is started</li>
<li><span class="code">TrainImages</span>, images to be used for training (<em>only for preprocessing mode</em>)</li>
<li><span class="code">TrainLabels</span>, labels accompanying images to be used for training (<em>only for preprocessing mode</em>)</li>
<li><span class="code">ValidationImages</span>, images to be used for validation during training (<em>only for preprocessing mode</em>)</li>
<li><span class="code">ValidationLabels</span>, labels accompanying images for validation (<em>only for preprocessing mode</em>)</li>
</ul>


</div>
</details>
<br>
<p><span class="h3">Label file details</span></p>
<p>
<img class="image-fit" src="images\DeepLearningDirs_panel4.png" alt=""> </p>

<ul>
<li>The <span class="kbd">[&#10003;] <b>Single MIB model file </b></span> checkbox, (<em>only for 2D networks</em>) when checked, a single model file with labels will be used</li>
<li>The <span class="dropdown">Labels extension &#9660;</span> dropdown, (<em>only for 2D networks</em>) is used to select extension of files containing models.
For 3D network MIB model format is used</li>
<li>The <b>Number of classes edit box</b>, (<em>TIF or PNG formats only</em>) is used to define number of classes (including <span class="code">Exterior</span>)
in labels. For label files in MIB <span class="code">*.model</span> format, this field will be updated automatically</li>
<li><span class="kbd">[&#10003;] <b>Use masking</b></span> checkbox is used when some parts of the training
data should be excluded from training. The masks may be provided in various formats
and number of mask files should match the number of image files. When
mask files are provided the preprocessing operation has to be done. When <span class="dropdown">USE 0-s IN LABELS &#9660;</span>
is selected the mask is assumed to be areas of label files with 0-values.
This option is recommended for work with masks without the preprocessing operation
<br>
<div class="info">
<ul>
<li> When <span class="dropdown">USE 0-s IN LABELS &#9660;</span> is used, the
first material in the prediction results will be assigned to the
Exterior material, i.e. will acquire index 0.
<br>
It is recommended to have the first material in the ground truth assigned to background!</li>
<li> When mask with the preprocessing operation is used, the Exterior material will be used to indicate the background areas</li>
<li> Masking may give drop in precision of training due to
inconsistency within the image patches, it is recommended to minimize use
of masking</li>
</ul>
</div>
</li>
<li><span class="dropdown">Mask extension &#9660;</span> is used to select extension for files that
contain masks. Without preprocessing (<span class="dropdown">USE 0-s IN LABELS &#9660;</span> any files are allowed);
with preprocessing only <span class="code">*.mask</span> format is
allowed for the 3D network</li>

<p><a id="target5"></a></p>
<p><span class="h3">Additional settings</span></p>
<p>
<img class="image-fit" src="images\DeepLearningDirs_panel5.png" alt=""> </p>

<ul>
<li><span class="kbd">[&#10003;] <b>Compress processed images</b></span>, tick to compress the processed images.
The processed images are stored in <em>*.mibImg</em> format that can be loaded in MIB.
<em>*.mibImg</em> is a variation of standard MATLAB format and can also be directly loaded into MATLAB
using similar to this command:
<br><span class="code">res = load('img01.mibImg, '-mat');</span>.

<br>
Compression of images slows down performance!</li>
<li><span class="kbd">[&#10003;] <b>Compress processed labels</b></span>, tick to compress labels during preprocessing.
The processed labels are stored in <em>*.mibCat</em> format that can be loaded in MIB (<em>Menu->Models->Load model</em>).
It is a variation of a standard MATLAB format, where the model is encoded using categorical class of MATLAB.

<br>
Compression of labels slows down performance but brings significant benefit of small file sizes</li>
<li><span class="kbd">[&#10003;] <b>Use parallel processing</b></span>, when ticked DeepMIB is using multiple
cores to process images. Number of cores can be specified using the
<span class="dropdown">Workers</span> edit box. The parallel processing during preprocessing
operation brings significant decrease in time required for
preprocessing.</li>
<li><span class="dropdown"><b>Fraction of images for validation</b></span>, define fraction of images
that will be randomly (depending on <span class="dropdown">Random generator seed</span>) assigned into
the validation set. When set to 0, the validation option will not be used during the training</li>
<li><span class="dropdown">Random generator seed</span>, a number to initialize random seed
generator, which defines how the images for training and validation are
split. For reproducibility of tests keep value fixed.
When random seed is initialized with 0, the random seed generator is shuffled based on the current system time</li>
<li><span class="dropdown">Preprocess for &#9660;</span>, select mode of operation upon press of the <span class="kbd">Preprocess</span> button.
Results of the preprocessing operation for each mode are presented in schemes below</li>
</ul>

<p><span style="line-height:32px; display:block; vertical-align:top">
<br></span></p>
<p style="margin:0px; line-height:0;">&nbsp;</p>
<p onclick="toggle_details(2)" class="collapse-link"><a href="javascript:void(0);" id="Toggle2">collapse all</a></p><h2 id="2">Preprocessing of files</h2>
<p><a id="target1"></a></p>
<p>
Originally, the preprocessing of files in DeepMIB was required for most of workflows.
Currently, however, DeepMIB is capable to work with unprocessed images most of
times: use the <span class="dropdown">Preprocessing is not required &#9660;</span> or
<span class="dropdown">Split for training/validation &#9660;</span> options.
</p>
<details open onclick="state_check('2.1')" id="2.1"><summary> <b>When the preprocessing step is required or recommended</b> </summary>
<div class="details-div">
<p></p>
<p>The preprocessing is recommended/required in the following situations:</p>
<div>
<ul>
<li>when labels are stored in a single <span class="code">*.MODEL</span> file</li>
<li>when training set is coming in proprietary formats that can only be read using BioFormats reader</li>
</ul>
</div>
<p>During preprocessing the images and model files are converted to <b>mibImg</b> and <b>mibCat</b> formats (a variation of MATLAB standard data format) that are adapted for training and prediction.</p>

</div>
</details>
<br>
<p> <span style="line-height:32px; display:block; vertical-align:top">
<br></span></p>
<p style="margin:0px; line-height:0;">&nbsp;</p>
<p onclick="toggle_details(3)" class="collapse-link"><a href="javascript:void(0);" id="Toggle3">collapse all</a></p><h2 id="3">Organization of directories without preprocessing for semantic segmentation</h2>
<p><span style="line-height:12px; display:block; vertical-align:top">
<br></span></p>
<p><span class="h3">Without preprocessing, when datasets are manually split into training and validation sets</span></p>
<p>In this mode, the training image files are not preprocessed and loaded on-demand during network training. The image files should be split into subfolders <span class="code">TrainImages, TrainLabels</span> and optional subfolders <span class="code">ValidationImages, ValidationLabels</span> (for details see Snapshot with the legend below). The images may also be automatically split, see <my-a onclick="jump_to()" href="#target4">the following section</my-a> for details. 
<br>When Bio-Format library is used, it is recommended to <my-a onclick="jump_to()" href="#target2">preprocess images</my-a> for the training process to speed up the file reading performance.</p>
<details open onclick="state_check('3.1')" id="3.1"><summary> <b>Snapshot with the directory tree</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_B.png" alt=""> </p>

</div>
</details>
<br>
<details open onclick="state_check('3.2')" id="3.2"><summary> <b>Snapshot with the legend</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_Legend.png" alt=""> </p>

</div>
</details>
<br>
<p> <span style="line-height:8px; display:block; vertical-align:top">
<br></span></p>
<p><span class="h3">Without preprocessing, with automatic splitting of datasets into training and validation sets</span></p>
<p>In this mode, the image and label files are randomly split into the train and validation sets. The split is done upon press of the <span class="kbd">Preprocess</span> button, when <span class="code">Preprocess for: Split for training and validation</span>
<br> Splitting of the files depends on a seed value provided in the <span class="code">Random generator seed</span> field; when seed is <b>0</b> a new random seed value is used each time the spliting is done.</p>
<details open onclick="state_check('3.3')" id="3.3"><summary> <b>Snapshot with the directory tree</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_C.png" alt=""> </p>

</div>
</details>
<br>
<p> <span style="line-height:8px; display:block; vertical-align:top">
<br></span></p>
<details open onclick="state_check('3.4')" id="3.4"><summary> <b>Snapshot with the legend</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_Legend.png" alt=""> </p>

</div>
</details>
<br>
<p> <span style="line-height:32px; display:block; vertical-align:top">
<br></span></p>
<p style="margin:0px; line-height:0;">&nbsp;</p>
<p onclick="toggle_details(4)" class="collapse-link"><a href="javascript:void(0);" id="Toggle4">collapse all</a></p><h2 id="4">Organization of directories with preprocessing for semantic segmentation</h2>
<p><a id="target2"></a> This mode is enabled when the <span class="code">Preprocess for</span> has one of the following selections:</p>
<div>
<ul>
<li>
<b>Training and prediction</b>, to preprocess images for both training and prediction</li>
<li>
<b>Training</b>, to preprocess images only for training</li>
<li>
<b>Prediction</b>, to preprocess images only for prediction</li>
</ul>
</div>
<p>The preprocessing starts by pressing of the <span class="kbd">Preprocess</span> button.</p>
<p>The scheme below demonstrates organization of directories, when the preprocessing mode is used.</p>
<details open onclick="state_check('4.1')" id="4.1"><summary> <b>Snapshot with the directory tree</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_A.png" alt=""> </p>

</div>
</details>
<br>
<details open onclick="state_check('4.2')" id="4.2"><summary> <b>Snapshot with the legend</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_Legend.png" alt=""> </p>

</div>
</details>
<br>
<p style="margin:0px; line-height:0;">&nbsp;</p>
<p onclick="toggle_details(5)" class="collapse-link"><a href="javascript:void(0);" id="Toggle5">collapse all</a></p><h2 id="5">Organization of directories for 2D patch-wise workflow</h2>
<p>The 2D patch-wise workflow requires slightly different organization of images in folders. In brief, instead having <span class="code">Images</span> and <span class="code">Labels</span> training directories, all images are organized in <span class="code">Images\[ClassnameN]</span> subfolders. Where <span class="code">ClassnameN</span> encodes a directory name with images patches that belong to <b>ClassnameN</b> class. Number of these subfolders should match number of classes to be used for training. <span style="line-height:16px; display:block; vertical-align:top">
<br></span></p>
<p>In contrast to semantic segmentation, the preprocessing is not used during the patch-wise mode.</p>
<p><span class="h3">Without preprocessing, when datasets are manually split into training and validation sets</span></p>
<p>The images for training should be organized in own subfolders named by corresponding class names and placed under:</p>
<div>
<ul>
<li><span class="code">1_Training\TrainImages</span>, images to be used for training</li>
<li><span class="code">1_Training\ValidationImages</span>, images to be used for validation (optionally)</li>
</ul>
</div>
<p>The images may also be <my-a onclick="jump_to()" href="#target4">automatically split</my-a> into subfolder for training and validation.</p>
<details open onclick="state_check('5.1')" id="5.1"><summary> <b>Snapshot with the directory tree</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_PW1.png" alt=""> </p>
<p><span class="code">bg</span> and <span class="code">spots</span> are examples of two class names</p>
<p>When the ground-truth data for prediction is present, it can be arranged in a similar way to the semantic segmentation under 
<br> <span class="code">2_Prediction\Images</span> and 
<br> <span class="code">2_Prediction\Labels</span> directories
<br> or in subfolders named by class names as <span class="code">2_Prediction\bg</span> and <span class="code">2_Prediction\spots</span>, where <span class="code">bg</span> and <span class="code">spots</span> subfolders contain patches that belong to these classes.</p>

</div>
</details>
<br>
<details open onclick="state_check('5.2')" id="5.2"><summary> <b>Snapshot with the legend</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_Legend.png" alt=""> </p>

</div>
</details>
<br>
<p> <span style="line-height:8px; display:block; vertical-align:top">
<br></span></p>
<p><a id="target4"></a> <span class="h3">Without preprocessing, with automatic splitting of datasets into training and validation sets</span></p>
<p>In this mode, the files are randomly split (depending on <my-a onclick="jump_to()" href="#target5">*Random generator seed*</my-a>) into the train and validation sets. The split is done upon press of the <span class="kbd">Preprocess</span> button, when <span class="code">Preprocess for: Split for training and validation</span><span style="line-height:8px; display:block; vertical-align:top">
<br></span> Initially, all images for training should be organized in own subfolders named by corresponding class names and placed under: <span class="code">1_Training\Images</span></p>
<details open onclick="state_check('5.3')" id="5.3"><summary> <b>Snapshot with the directory tree</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_PW2.png" alt=""> </p>
<p><span class="code">bg</span> and <span class="code">spots</span> are examples of two class names</p>
<p>When the ground-truth data for prediction is present, it can be arranged in a similar way to the semantic segmentation under 
<br> <span class="code">2_Prediction\Images</span> and 
<br> <span class="code">2_Prediction\Labels</span> directories
<br> or in subfolders named by class names as <span class="code">2_Prediction\bg</span> and <span class="code">2_Prediction\spots</span>, where <span class="code">bg</span> and <span class="code">spots</span> subfolders contain patches that belong to these classes.</p>

</div>
</details>
<br>
<p> <span style="line-height:8px; display:block; vertical-align:top">
<br></span></p>
<details open onclick="state_check('5.4')" id="5.4"><summary> <b>Snapshot with the legend</b> </summary>
<div class="details-div">
<p></p>
<p>
<img class="image-fit" src="images\DeepLearningDirectories_Legend.png" alt=""> </p>

</div>
</details>
<br>
<p> <span style="line-height:32px; display:block; vertical-align:top">
<br></span></p>
<p>
<b>Back to</b> <a href="im_browser_product_page.html"><b>Index</b></a> <code><b>--&gt;</b></code> <a href="im_browser_user_guide.html"><b>User Guide</b></a> <code><b>--&gt;</b></code> <a href="ug_gui_menu.html"><b>Menu</b></a> <code><b>--&gt;</b></code> <a href="ug_gui_menu_tools.html"><b>Tools Menu</b></a> <code><b>--&gt;</b></code> <a href="ug_gui_menu_tools_deeplearning.html"><b>Deep learning segmentation</b></a>
</p>
<p></p>
<p>
<script>
  var allDetails = document.getElementsByTagName('details');
  toggle_details(0);
</script>
</p>
<p class="footer">

<br>
<a href="https://www.mathworks.com/products/matlab/">Published with MATLAB&reg; R2023b</a> and subsequently processed by <a class="pretty-link" href="https://www.mathworks.com/matlabcentral/fileexchange/78059-prettify-matlab-html">prettify_MATLAB_html</a> V6.8b2</p>
<p id="iFrameBuf">&nbsp;</p>
</div>
<!--
##### SOURCE BEGIN #####
%% DeepMIB - Directories and Preprocessing tab
% This tab allows choosing directories with images for training and
% prediction as well as various parameters used during image loading and
% preprocessing
% 
% *Back to* <im_browser_product_page.html *Index*> |*REPLACE_WITH_DASH_DASH>*| <im_browser_user_guide.html *User Guide*> 
% |*REPLACE_WITH_DASH_DASH>*| <ug_gui_menu.html *Menu*> |*REPLACE_WITH_DASH_DASH>*| <ug_gui_menu_tools.html *Tools
% Menu*> |*REPLACE_WITH_DASH_DASH>*| <ug_gui_menu_tools_deeplearning.html *Deep learning segmentation*>
% 
% 
%% Widgets and settings
%
% <<images\DeepLearning_FileTree.jpg>>
%
% [class.h3]Directory with images and labels for training[/class]
<br>
% [ _used only for training_ ]
<br>
% 
% <<images\DeepLearningDirs_panel1.png>>
% 
% <html lang="en">
% use these widgets to select directory that contain images and model to be
% used for training. For the organization of directories see the
% organization schemes below.
<br>
% For 2D networks the files should contain individual 2D images, while for 3D networks
% individual 3D datasets.
<br>
% The <span class="dropdown">extension &#9660;</span> dropdown menu on the right-hand side can be used to specify extension 
% of the image files. 
<br>
% The <span class="kbd">[&#10003;] <b>Bio</b></span> checkbox toggles standard or Bio-format readers for loading images. 
% If the Bio-Format file is a collection of image, the <span class="dropdown">Index...</span> edit box can be used
% to specify an index of the file within the container.
<br>
% For better performance, it is recommended to convert Bio-Formats compatible images to standard formats or to use the Preprocessing option (see below). 
% 
<br>
% </html>
%
% [dtls]<summary> *Important notes considering training files* </summary>
<div class="details-div">
%
% <html lang="en">
% <ul>
% <li>Number of model or mask files should match the number of image files
% (one exception is 2D networks, where it is allowed to have a single
% model file in MIB <span class="code">*.model</span> format, when <b>Single MIB model file:
% ticked</b>). This option requires [jumpto2]data preprocessing[/jumpto]</li> 
% <li>For labels in standard image formats it is important to
% specify number of classes <b>including the Exterior</b> into the <b>Number of
% classes</b> edit box</li>
% <li><b><em>Important! It is not possible to use numbers as names of
% materials, please name materials in a sensible way when using the <span class="code">*.model</span> format!</b></em></li>
% </ul>
% </html>
%
% [/dtls]
% [br8]
% 
% [class.h3]Directory with images for prediction[/class]
<br>
% [ _used only for prediction_ ]
<br>
% use these widgets to specify directory with images for prediction (named [class.code]2_Prediction[/class] in [jumpto1]the file organization schemes below[/jumpto]).
% 
% <<images\DeepLearningDirs_panel2.png>>
% 
% <html lang="en">
% The image files should be placed under <span class="code">Images</span> subfolder 
% (it is also possible to place images directly into a folder specified in this panel). 
% Optionally, when the ground truth labels for prediction images are available, they can be placed under <span class="code">Labels</span> subfolder.
% 
<br>
<br>
% When the preprocessing mode is used the images from this folder are
% converted and saved to <span class="code">3_Results\Prediction images</span> directory. 
% When the ground truth labels are present, they are also processed and copied to 
% <span class="code">3_Results\PredictionImages\GroundTruthLabels</span>. These labels can
% be used for evaluation of results (see <ug_gui_menu_tools_deeplearning_predict.html the *Predict* tab> for details).
% 
<br>
<br>
% For 2D networks the files should contain individual 2D images or 3D stacks, while for 3D networks
% individual 3D datasets.
% 
<br>
<br>
% The <span class="dropdown">extension &#9660;</span> dropdown menu on the right-hand side can be used to specify extension 
% of the image files. The <span class="kbd">[&#10003;] <b>Bio</b></span> checkbox toggles standard or Bio-format readers for loading the images. 
% If the Bio-Format file is a collection of image, the <b>Index</b> edit box can be used
% to specify an index of the file within the container.
<br>
% </html>
%
% [br8]
% [class.h3]Directory with resulting images[/class]
<br>
% use these widgets to specify the main output directory; results and all
% preprocessed images are stored there.
% 
% <<images\DeepLearningDirs_panel3.png>>
%
% All subfolders inside this
% directory are automatically created by Deep MIB:[br8]
%
% [dtls]<summary> *Description of directories created by DeepMIB* </summary>
<div class="details-div">
%
% <html lang="en">
% <ul>
% <li><span class="code">PredictionImages</span>, place for the prepocessed images for
% prediction</li>
% <li><span class="code">PredictionImages\GroundTruthLabels</span>, place
% for ground truth labels for prediction images, when available</li>
% <li><span class="code">PredictionImages\ResultsModels</span>, the main outout directory with generated labels after prediction. 
% The 2D models can be combined in MIB by selecting the files using the <span class="kbd">&#8679; Shift</span>+<span class="kbd">left mouse click</span> during loading</li>
% <li><span class="code">PredictionImages\ResultsScores</span>, folder for generated prediction scores (probability) for each material. 
% The score values are scaled between 0 and 255</li>
% <li><span class="code">ScoreNetwork</span>, for accuracy and loss score plots, when the <em>Export training plots</em> option 
% of the <em>Train</em> tab is ticked and for storing checkpoints of the network after each epoch (or specified frequency), 
% when the <span class="kbd">[&#10003;] <b>Save progress after each epoch</b></span> checkbox is ticked. The score files are started with a date-time tag and overwritten when a new training is started</li>
% <li><span class="code">TrainImages</span>, images to be used for training (<em>only for preprocessing mode</em>)</li>
% <li><span class="code">TrainLabels</span>, labels accompanying images to be used for training (<em>only for preprocessing mode</em>)</li>
% <li><span class="code">ValidationImages</span>, images to be used for validation during training (<em>only for preprocessing mode</em>)</li>
% <li><span class="code">ValidationLabels</span>, labels accompanying images for validation (<em>only for preprocessing mode</em>)</li>
% </ul>
% </html>
%
% [/dtls]
%
% [class.h3]Label file details[/class]
% 
% <<images\DeepLearningDirs_panel4.png>>
%
% <html lang="en">
% <ul>
% <li>The <span class="kbd">[&#10003;] <b>Single MIB model file </b></span> checkbox, (<em>only for 2D networks</em>) when checked, a single model file with labels will be used</li>
% <li>The <span class="dropdown">Labels extension &#9660;</span> dropdown, (<em>only for 2D networks</em>) is used to select extension of files containing models.
% For 3D network MIB model format is used</li>
% <li>The <b>Number of classes edit box</b>, (<em>TIF or PNG formats only</em>) is used to define number of classes (including <span class="code">Exterior</span>) 
% in labels. For label files in MIB <span class="code">*.model</span> format, this field will be updated automatically</li>
% <li><span class="kbd">[&#10003;] <b>Use masking</b></span> checkbox is used when some parts of the training 
% data should be excluded from training. The masks may be provided in various formats
% and number of mask files should match the number of image files. When
% mask files are provided the preprocessing operation has to be done. When <span class="dropdown">USE 0-s IN LABELS &#9660;</span>
% is selected the mask is assumed to be areas of label files with 0-values.
% This option is recommended for work with masks without the preprocessing operation
<br>
% <div class="info">
% <ul>
% <li> When <span class="dropdown">USE 0-s IN LABELS &#9660;</span> is used, the
% first material in the prediction results will be assigned to the
% Exterior material, i.e. will acquire index 0.
<br>
% It is recommended to have the first material in the ground truth assigned to background!</li>
% <li> When mask with the preprocessing operation is used, the Exterior material will be used to indicate the background areas</li>
% <li> Masking may give drop in precision of training due to
% inconsistency within the image patches, it is recommended to minimize use
% of masking</li>
% </ul>
% </div>
% </li>
% <li><span class="dropdown">Mask extension &#9660;</span> is used to select extension for files that
% contain masks. Without preprocessing (<span class="dropdown">USE 0-s IN LABELS &#9660;</span> any files are allowed); 
% with preprocessing only <span class="code">*.mask</span> format is
% allowed for the 3D network</li>
% </html>
%
% [target5]
%
% [class.h3]Additional settings[/class]
% 
% <<images\DeepLearningDirs_panel5.png>>
% 
% <html lang="en">
% <ul>
% <li><span class="kbd">[&#10003;] <b>Compress processed images</b></span>, tick to compress the processed images. 
% The processed images are stored in <em>*.mibImg</em> format that can be loaded in MIB. 
% <em>*.mibImg</em> is a variation of standard MATLAB format and can also be directly loaded into MATLAB 
% using similar to this command:
<br><span class="code">res = load('img01.mibImg, '-mat');</span>.
% 
<br>
% Compression of images slows down performance!</li>
% <li><span class="kbd">[&#10003;] <b>Compress processed labels</b></span>, tick to compress labels during preprocessing. 
% The processed labels are stored in <em>*.mibCat</em> format that can be loaded in MIB (<em>Menu->Models->Load model</em>). 
% It is a variation of a standard MATLAB format, where the model is encoded using categorical class of MATLAB.
% 
<br> 
% Compression of labels slows down performance but brings significant benefit of small file sizes</li>
% <li><span class="kbd">[&#10003;] <b>Use parallel processing</b></span>, when ticked DeepMIB is using multiple
% cores to process images. Number of cores can be specified using the
% <span class="dropdown">Workers</span> edit box. The parallel processing during preprocessing
% operation brings significant decrease in time required for
% preprocessing.</li>
% <li><span class="dropdown"><b>Fraction of images for validation</b></span>, define fraction of images
% that will be randomly (depending on <span class="dropdown">Random generator seed</span>) assigned into
% the validation set. When set to 0, the validation option will not be used during the training</li>
% <li><span class="dropdown">Random generator seed</span>, a number to initialize random seed
% generator, which defines how the images for training and validation are
% split. For reproducibility of tests keep value fixed. 
% When random seed is initialized with 0, the random seed generator is shuffled based on the current system time</li>
% <li><span class="dropdown">Preprocess for &#9660;</span>, select mode of operation upon press of the <span class="kbd">Preprocess</span> button. 
% Results of the preprocessing operation for each mode are presented in schemes below</li>
% </ul>
% </html>
%
% [br32]
%
%% Preprocessing of files
% 
% [target1]
%
% <html lang="en">
% Originally, the preprocessing of files in DeepMIB was required for most of workflows. 
% Currently, however, DeepMIB is capable to work with unprocessed images most of 
% times: use the <span class="dropdown">Preprocessing is not required &#9660;</span> or 
% <span class="dropdown">Split for training/validation &#9660;</span> options.
% </html>
%
% [dtls]<summary> *When the preprocessing step is required or recommended* </summary>
<div class="details-div">
%
% The preprocessing is recommended/required in the following situations:
%
% * when labels are stored in a single [class.code]*.MODEL[/class] file
% * when training set is coming in proprietary formats that can only be read using BioFormats reader
%
% During preprocessing the images and model files are converted to 
% *mibImg* and *mibCat* formats (a variation of MATLAB standard data format) that are adapted for training and prediction.
%
% [/dtls]
% [br32]
%
%% Organization of directories without preprocessing for semantic segmentation
%
% [br12]
%
% [class.h3]Without preprocessing, when datasets are manually split into training
% and validation sets[/class]
%
% In this mode, the training image files are not preprocessed and loaded on-demand during network training. 
% The image files should be split into subfolders [class.code]TrainImages, TrainLabels[/class] 
% and optional subfolders [class.code]ValidationImages,
% ValidationLabels[/class] (for details see Snapshot with the legend below). The images may also be automatically split, see
% [jumpto4]the following section[/jumpto] for details.
% 
<br>When Bio-Format library is used, it is
% recommended to [jumpto2]preprocess images[/jumpto] for the training process to speed up the
% file reading performance.
%
% [dtls]<summary> *Snapshot with the directory tree* </summary>
<div class="details-div">
% 
% <<images\DeepLearningDirectories_B.png>>
% 
% [/dtls]
%
% [dtls]<summary> *Snapshot with the legend* </summary>
<div class="details-div">
%
% <<images\DeepLearningDirectories_Legend.png>>
%
% [/dtls]
% [br8]
%
% [class.h3]Without preprocessing, with automatic splitting of datasets
% into training and validation sets[/class]
%
% In this mode, the image and label files are randomly
% split into the train and validation sets. The split is done upon press of
% the [class.kbd]Preprocess[/class] button, when [class.code]Preprocess
% for: Split for training and validation[/class]
<br>
% Splitting of the files depends on a seed value provided in the
% [class.code]Random generator seed[/class] field; when seed is *0* a new
% random seed value is used each time the spliting is done.
%
% [dtls]<summary> *Snapshot with the directory tree* </summary>
<div class="details-div">
%
% <<images\DeepLearningDirectories_C.png>>
%
% [/dtls]
% [br8]
% 
% [dtls]<summary> *Snapshot with the legend* </summary>
<div class="details-div">
%
% <<images\DeepLearningDirectories_Legend.png>>
%
% [/dtls]
% [br32]
%
%% Organization of directories with preprocessing for semantic segmentation
%
% [target2]
% This mode is enabled when the [class.code]Preprocess for[/class] has one of the following selections:
%
% * *Training and prediction*, to preprocess images for both training and
% prediction
% * *Training*, to preprocess images only for training
% * *Prediction*, to preprocess images only for prediction
%
% The preprocessing starts by pressing of the [class.kbd]Preprocess[/class]
% button.
%
% The scheme below demonstrates organization of directories, when the preprocessing mode is used. 
%
% [dtls]<summary> *Snapshot with the directory tree* </summary>
<div class="details-div">
%
% <<images\DeepLearningDirectories_A.png>>
%
% [/dtls]
%
% [dtls]<summary> *Snapshot with the legend* </summary>
<div class="details-div">
% 
% <<images\DeepLearningDirectories_Legend.png>>
% 
% [/dtls]
%
%
%% Organization of directories for 2D patch-wise workflow
%
% The 2D patch-wise workflow requires slightly different organization of
% images in folders. In brief, instead having [class.code]Images[/class]
% and [class.code]Labels[/class] training directories, all images are organized in
% [class.code]Images\[ClassnameN][/class] subfolders. Where
% [class.code]ClassnameN[/class] encodes a directory name with images patches that belong to
% *ClassnameN* class. Number of these subfolders should match number of
% classes to be used for training.
% [br16]
%
% In contrast to semantic segmentation, the preprocessing is not used
% during the patch-wise mode.
%
% [class.h3]Without preprocessing, when datasets are manually split into training
% and validation sets[/class]
%
% The images for training should be organized in own subfolders named by
% corresponding class names and placed under:
% 
% * [class.code]1_Training\TrainImages[/class], images to be used for training
% * [class.code]1_Training\ValidationImages[/class], images to be used for
% validation (optionally)
% 
% The images may also be [jumpto4]automatically split[/jumpto] into subfolder for training
% and validation.
%
% [dtls]<summary> *Snapshot with the directory tree* </summary>
<div class="details-div">
% 
% <<images\DeepLearningDirectories_PW1.png>>
% 
% [class.code]bg[/class] and [class.code]spots[/class] are examples of two class names
%
% When the ground-truth data for prediction is present, it can be arranged
% in a similar way to the semantic segmentation under 
<br>
% [class.code]2_Prediction\Images[/class] and 
<br>
% [class.code]2_Prediction\Labels[/class] directories
<br>
% or in subfolders named by class names as
% [class.code]2_Prediction\bg[/class] and
% [class.code]2_Prediction\spots[/class], where [class.code]bg[/class] and
% [class.code]spots[/class] subfolders contain patches that belong to these
% classes.
%
% [/dtls]
%
% [dtls]<summary> *Snapshot with the legend* </summary>
<div class="details-div">
%
% <<images\DeepLearningDirectories_Legend.png>>
%
% [/dtls]
% [br8]
%
% [target4]
% [class.h3]Without preprocessing, with automatic splitting of datasets
% into training and validation sets[/class]
%
% In this mode, the files are randomly split (depending on [jumpto5]*Random generator seed*[/jumpto]) into the train and validation sets.
% The split is done upon press of the [class.kbd]Preprocess[/class] button,
% when [class.code]Preprocess for: Split for training and validation[/class][br8]
% Initially, all images for training should be organized in own subfolders named by
% corresponding class names and placed under: [class.code]1_Training\Images[/class]
%
% [dtls]<summary> *Snapshot with the directory tree* </summary>
<div class="details-div">
%
% <<images\DeepLearningDirectories_PW2.png>>
% 
% [class.code]bg[/class] and [class.code]spots[/class] are examples of two class names
%
% When the ground-truth data for prediction is present, it can be arranged
% in a similar way to the semantic segmentation under 
<br>
% [class.code]2_Prediction\Images[/class] and 
<br>
% [class.code]2_Prediction\Labels[/class] directories
<br>
% or in subfolders named by class names as
% [class.code]2_Prediction\bg[/class] and
% [class.code]2_Prediction\spots[/class], where [class.code]bg[/class] and
% [class.code]spots[/class] subfolders contain patches that belong to these
% classes.
%
%
% [/dtls]
% [br8]
% 
% [dtls]<summary> *Snapshot with the legend* </summary>
<div class="details-div">
%
% <<images\DeepLearningDirectories_Legend.png>>
%
% [/dtls]
% [br32]
%
% 
% *Back to* <im_browser_product_page.html *Index*> |*REPLACE_WITH_DASH_DASH>*| <im_browser_user_guide.html *User Guide*> 
% |*REPLACE_WITH_DASH_DASH>*| <ug_gui_menu.html *Menu*> |*REPLACE_WITH_DASH_DASH>*| <ug_gui_menu_tools.html *Tools
% Menu*> |*REPLACE_WITH_DASH_DASH>*| <ug_gui_menu_tools_deeplearning.html *Deep learning segmentation*>
%
%%
% [cssClasses]
% .dropdown { 
%   font-family: monospace;
% 	border: 1px solid #aaa; 
% 	border-radius: 0.2em; 
% 	background-color: #fffce8; 
% 	padding: 0.1em 0.4em; 
% 	font-family: inherit; 
% 	font-size: 1em;
% }
% .kbd { 
%   font-family: monospace;
% 	border: 1px solid #aaa; 
% 	-moz-border-radius: 0.2em; 
% 	-webkit-border-radius: 0.2em; 
% 	border-radius: 0.2em; 
% 	-moz-box-shadow: 0.1em 0.2em 0.2em #ddd; 
% 	-webkit-box-shadow: 0.1em 0.2em 0.2em #ddd; 
% 	box-shadow: 0.1em 0.2em 0.2em #ddd; 
% 	background-color: #f9f9f9; 
% 	background-image: -moz-linear-gradient(top, #eee, #f9f9f9, #eee); 
% 	background-image: -o-linear-gradient(top, #eee, #f9f9f9, #eee); 
% 	background-image: -webkit-linear-gradient(top, #eee, #f9f9f9, #eee); 
% 	background-image: linear-gradient(&#91;&#91;:Template:Linear-gradient/legacy]], #eee, #f9f9f9, #eee); 
% 	padding: 0.1em 0.4em; 
% 	font-family: inherit; 
% 	font-size: 1em;
% }
% .h3 {
% color: #E65100;
% font-size: 12px;
% font-weight: bold;
% }
% .code {
% font-family: monospace;
% font-size: 10pt;
% background: #eee;
% padding: 1pt 3pt;
% }
% .info {
%  position: relative;
%  left: 40px;
%  width: 600px;
%  padding: 1em 1em 1em 4em;
%  margin: 2em 0;
%  color: #555;
%  background: #e7f2fa;
%  border-left: 4px solid #93cfeb;
% }
% .info:before {
%  content: url(images\\info.png);
%  position: absolute;
%  top: 10px;
%  left: 10px;
% }
% [/cssClasses]
%
%
% <html lang="en">
% <script>
%   var allDetails = document.getElementsByTagName('details');
%   toggle_details(0);
% </script>
% </html>
##### SOURCE END #####
-->
<script>
var allDetails   = document.getElementsByTagName('details');
var contentDiv   = document.getElementsByClassName("content"); contentDiv = contentDiv[0];
var returnButton = document.getElementById("return-link");
document.getElementById("iFrameBuf").style.display = "none";
if(in_iFrame())
{
   try{
      var footerNav = parent.document.getElementsByClassName("footernav");
      var tabPane   = parent.document.getElementsByClassName("tab-pane");}
   catch(err) { var footerNav = []; var tabPane = [];};
   if(!(footerNav.length) || tabPane.length)
   {
      contentDiv.style.overflowY = "scroll";
      contentDiv.style.overflowX = "hidden";
      contentDiv.style.position  = "absolute";
      contentDiv.style.width     = "95%";
      contentDiv.style.top       = 0;
      contentDiv.style.bottom    = 0;
      if (tabPane.length){
         contentDiv.setAttribute("data-isMATLABCentral","1");
         returnButton.style.right = "40px";
         document.getElementById("tooltiptext").style.right = "92px"; }
      document.getElementById("iFrameBuf").style.display = "block";
   }
   else { contentDiv.setAttribute("data-isHelpBrowser","1"); }
}
if (!contentDiv.getAttribute("data-isHelpBrowser") && !contentDiv.getAttribute("data-isMATLABCentral") ){
   document.getElementById("anchor-offsets").sheet.disabled = true; }
</script></body>
</html>
